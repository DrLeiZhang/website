---
layout: default
---
<img class="about-avatar" src="{{ "/img/object.jpg" | prepend: site.baseurl }}" border="0" alt="[name]" />

<div class="well">
<p><a href="http://www.leizhang.tk/">{Home}</a> <a href="http://www.leizhang.tk/publications%20and%20codes.html">{Publications and Codes}</a> <a href="http://www.leizhang.tk/research.html">{Research}</a> <a href="http://www.leizhang.tk/projects.html"><B>{Projects}</B></a> <a href="http://www.leizhang.tk/professional%20activities.html">{Professional Activities}</a> <a href="http://www.leizhang.tk/people.html">{People}</a></p>
</div>

<div class="well">
<h2>Machine Olfaction, Signal Processing and Pattern Recognition</h2>

<h1>[Semi-supervised Learning in Electronic Nose]</a></h1>
<p><B>Paper:</B> </p>
<p>Lei Zhang*, David Zhang, Xin Yin, and Yan Liu, A Novel Semi-Supervised Learning Approach in Artificial Olfaction for E-Nose Application, IEEE Sensors Journal, vol. 16, no. 12, pp. 4919-4931, 2016. <a href="resources/IEEE_MFKS.pdf">[paper]</a></p>

<p><B>Abstract:</B></p>
<p>Artificial olfaction data are usually represented by
a sensor array embedded in an electronic nose system (E-Nose),
such that each observation can be expressed as a feature
vector for pattern recognition. The concerns of this paper are
threefold: 1) each feature can be represented by multiple different
modalities; 2) manual labeling of sensory data in real application
is difficult and hardly impossible, which results in an issue of
insufficient labeled data; and 3) classifier learning is generally
independent of feature engineering, such that the recognition
capability of E-Nose is restricted due to the unilateral suboptimum.
Motivated by these concerns, in this paper, from a new
perspective of multi-task learning, we aim at proposing a unified
semi-supervised learning framework nominated as MFKS, and
the merits are composed of three points. First, a multi-feature
joint classifier learning with low-rank constraint is developed
for exploiting the structural information of multiple feature
modalities. The relatedness of sub-classifiers with respect to
feature modalities is preserved by imposing a low-rank constraint
on the group classifier. Second, with a manifold assumption,
a Laplacian graph manifold regularization is incorporated for
capturing the intrinsic geometry of unlabeled data. Third, the
features and classifiers are learned simultaneously in a unified
framework, such that the optimality and robustness are
improved. Experiments on two data sets, including large-scale
16-sensor data with 36-month drift and small-scale temperature
modulated sensory data, demonstrate that the proposed approach
has 4% improvement in classification accuracy than others.</p>
<img class="about-avatar" src="{{ "/img/proj14_1.jpg" | prepend: site.baseurl }}" border="0" alt="[name]" />

<p><B>Approach:</B></p>
<p>Framework</p>
<img class="about-avatar" src="{{ "/img/proj14_1.jpg" | prepend: site.baseurl }}" border="0" alt="[name]" />
<p>Multi-feature construction</p>
<img class="about-avatar" src="{{ "/img/proj14_2.jpg" | prepend: site.baseurl }}" border="0" alt="[name]" />
<img class="about-avatar" src="{{ "/img/proj14_3.jpg" | prepend: site.baseurl }}" border="0" alt="[name]" />
<p><B>Experimental Results</B></p>
<img class="about-avatar" src="{{ "/img/proj14_4.jpg" | prepend: site.baseurl }}" border="0" alt="[name]" />
<img class="about-avatar" src="{{ "/img/proj14_5.jpg" | prepend: site.baseurl }}" border="0" alt="[name]" />

<p><B>References:</B></p>
<p>[1] D. Zhou, O. Bousquet, T. Navin Lal, J. Weston, and B. Schölkopf,
“Learning with local and global consistency,” in Proc. NIPS, 2004,
pp. 321–328.</p>
<p>[2] Y. Luo, D. Tao, B. Geng, C. Xu, and S. J. Maybank, “Manifold
regularized multitask learning for semi-supervised multilabel image
classification,” IEEE Trans. Image Process., vol. 22, no. 2, pp. 523–536,
Feb. 2013.</p>
<p>[3] M. Belkin and P. Niyogi, “Laplacian eigenmaps for dimensionality
reduction and data representation,” Neural Comput., vol. 15, no. 6,
pp. 1373–1396, 2003.</p>
<p>[4] S. Yan, D. Xu, B. Zhang, H.-J. Zhang, Q. Yang, and S. Lin, “Graph
embedding and extensions: A general framework for dimensionality
reduction,” IEEE Trans. Pattern Anal. Mach. Intell., vol. 29, no. 1,
pp. 40–51, Jan. 2007.</p>

</div>



