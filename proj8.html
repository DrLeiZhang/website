---
layout: default
---
<img class="about-avatar" src="{{ "/img/object.jpg" | prepend: site.baseurl }}" border="0" alt="[name]" />

<div class="well">
<p><a href="http://www.leizhang.tk/">{Home}</a> <a href="http://www.leizhang.tk/publications%20and%20codes.html">{Publications and Codes}</a> <a href="http://www.leizhang.tk/research.html">{Research}</a> <a href="http://www.leizhang.tk/projects.html"><B>{Projects}</B></a> <a href="http://www.leizhang.tk/professional%20activities.html">{Professional Activities}</a> <a href="http://www.leizhang.tk/people.html">{People}</a></p>
</div>

<div class="well">
<h2>Machine Vision, Image Recognition and Machine Learning</h2>

<h1>[Facial Attractiveness/Beauty Analysis]</a></h1>
<p><B>Paper:</B> </p>
<p>Lei Zhang*, Jian Yang, and David Zhang, Domain class consistency based transfer learning for image classification across domains, Information Sciences, vol. 418-419, pp. 242-257, 2017. <a href="resources/IS_Accept.pdf">[paper]</a></p>

<p><B>Abstract:</B></p>
<p>Distribution mismatch between the modeling data and the query data is a known domain adaptation issue in machine learning. To this end, in this paper, we propose a l 2,1 -norm based discriminative robust kernel transfer learning (DKTL) method for high-level recog- nition tasks. The key idea is to realize robust domain transfer by simultaneously integrat- ing domain-class-consistency (DCC) metric based discriminative subspace learning, kernel learning in reproduced kernel Hilbert space, and representation learning between source and target domain. The DCC metric includes two properties: domain-consistency used to measure the between-domain distribution discrepancy and class-consistency used to mea- sure the within-domain class separability. The essential objective of the proposed trans- fer learning method is to maximize the DCC metric, which is equivalently to minimize the domain-class-inconsistency (DCIC), such that domain distribution mismatch and class inseparability are well formulated and unified simultaneously. The merits of the proposed method include (1) the robust sparse coding selects a few valuable source data with noises (outliers) removed during knowledge transfer, and (2) the proposed DCC metric can pur- sue more discriminative subspaces of different domains. As a result, the maximum class- separability is also well guaranteed. Extensive experiments on a number of visual datasets demonstrate the superiority of the proposed method over other state-of-the-art domain adaptation and transfer learning methods.</p>

<img class="about-avatar" src="{{ "/img/proj8_1.jpg" | prepend: site.baseurl }}" border="0" alt="[name]" />

<p><B>Approach:</B></p>
<img class="about-avatar" src="{{ "/img/proj8_2.jpg" | prepend: site.baseurl }}" border="0" alt="[name]" />

<p><B>Datasets:</B></p>
<img class="about-avatar" src="{{ "/img/proj8_3.jpg" | prepend: site.baseurl }}" border="0" alt="[name]" />
<img class="about-avatar" src="{{ "/img/proj8_4.jpg" | prepend: site.baseurl }}" border="0" alt="[name]" />
<img class="about-avatar" src="{{ "/img/proj8_5.jpg" | prepend: site.baseurl }}" border="0" alt="[name]" />

<p><B>Experiments:</B></p>
<img class="about-avatar" src="{{ "/img/proj8_6.jpg" | prepend: site.baseurl }}" border="0" alt="[name]" />
<img class="about-avatar" src="{{ "/img/proj8_7.jpg" | prepend: site.baseurl }}" border="0" alt="[name]" />
<img class="about-avatar" src="{{ "/img/proj8_8.jpg" | prepend: site.baseurl }}" border="0" alt="[name]" />

<p><B>References:</B></p>
<p>[1] L. Zhang, S.K. Jha, T. Liu, G. Pei, Discriminative kernel transfer learning via l 2,1 -norm minimization, in: IJCNN, 2016, pp. 2220–2227 .</p>
<p>[2] L. Zhang, W. Zuo, D. Zhang, LSDT: latent sparse domain transfer learning for visual adaptation, IEEE Trans. Image Process. 25 (3) (2016) 1177–1191 .</p>
<p>[3] M. Shao, D. Kit, Y. Fu, Generalized transfer subspace learning through low-rank constraint, Int. J. Comput. Vis. 109 (2014) 74–93 .</p>
<p>[4] M. Long, H. Zhu, J. Wang, M.I. Jordan, Unsupervised domain adaptation with residual transfer networks, NIPS, 2016 .</p>
<p>[5] I.H. Jhuo, D. Liu, D. Lee, S.F. Chang, Robust visual domain adaptation with low-rank reconstruction, in: CVPR, 2012, pp. 2168–2175.</p>
</div>



