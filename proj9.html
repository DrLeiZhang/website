---
layout: default
---
<img class="about-avatar" src="{{ "/img/object.jpg" | prepend: site.baseurl }}" border="0" alt="[name]" />

<div class="well">
<p><a href="http://www.leizhang.tk/">{Home}</a> <a href="http://www.leizhang.tk/publications%20and%20codes.html">{Publications and Codes}</a> <a href="http://www.leizhang.tk/research.html">{Research}</a> <a href="http://www.leizhang.tk/projects.html"><B>{Projects}</B></a> <a href="http://www.leizhang.tk/professional%20activities.html">{Professional Activities}</a> <a href="http://www.leizhang.tk/people.html">{People}</a></p>
</div>

<div class="well">
<h2>Machine Vision, Image Recognition and Machine Learning</h2>

<h1>[Cost-sensitive Learning and Recognition]</a></h1>
<p><B>Paper:</B> </p>
<p>Lei Zhang* and David Zhang, Evolutionary Cost-Sensitive Extreme Learning Machine, IEEE Transactions on Neural Networks and Learning Systems, 2016, doi: 10.1109/TNNLS.2016.2607757. <a href="resources/ECSELM.pdf">[paper]</a></p>

<p><B>Abstract:</B></p>
<p>Conventional extreme learning machines (ELMs)
solve a Moore–Penrose generalized inverse of hidden layer
activated matrix and analytically determine the output weights
to achieve generalized performance, by assuming the same loss
from different types of misclassification. The assumption may not
hold in cost-sensitive recognition tasks, such as face recognitionbased
access control system, where misclassifying a stranger
as a family member may result in more serious disaster than
misclassifying a family member as a stranger. Though recent
cost-sensitive learning can reduce the total loss with a given cost
matrix that quantifies how severe one type of mistake against
another, in many realistic cases, the cost matrix is unknown
to users. Motivated by these concerns, this paper proposes
an evolutionary cost-sensitive ELM, with the following merits:
1) to the best of our knowledge, it is the first proposal of ELM
in evolutionary cost-sensitive classification scenario; 2) it well
addresses the open issue of how to define the cost matrix in
cost-sensitive learning tasks; and 3) an evolutionary backtracking
search algorithm is induced for adaptive cost matrix optimization.
Experiments in a variety of cost-sensitive tasks well demonstrate
the effectiveness of the proposed approaches, with about
5%–10% improvements.</p>
<img class="about-avatar" src="{{ "/img/proj9_1.jpg" | prepend: site.baseurl }}" border="0" alt="[name]" />

<p><B>Datasets:</B></p>
<img class="about-avatar" src="{{ "/img/proj9_2.jpg" | prepend: site.baseurl }}" border="0" alt="[name]" />
<img class="about-avatar" src="{{ "/img/proj9_3.jpg" | prepend: site.baseurl }}" border="0" alt="[name]" />

<p><B>Experiments:</B></p>
<img class="about-avatar" src="{{ "/img/proj9_4.jpg" | prepend: site.baseurl }}" border="0" alt="[name]" />
<img class="about-avatar" src="{{ "/img/proj9_5.jpg" | prepend: site.baseurl }}" border="0" alt="[name]" />
<img class="about-avatar" src="{{ "/img/proj9_6.jpg" | prepend: site.baseurl }}" border="0" alt="[name]" />
<img class="about-avatar" src="{{ "/img/proj9_7.jpg" | prepend: site.baseurl }}" border="0" alt="[name]" />

<p><B>References:</B></p>
<p>[1] G.-B. Huang, Q.-Y. Zhu, and C.-K. Siew, “Extreme learning
machine: Theory and applications,” Neurocomputing, vol. 70, nos. 1–3,
pp. 489–501, 2006.</p>
<p>[2] L. Zhang and F. Tian, “Performance study of multilayer perceptrons in
a low-cost electronic nose,” IEEE Trans. Instrum. Meas., vol. 63, no. 7,
pp. 1670–1679, Jul. 2014.</p>
<p>[3] J. Lu and Y. P. Tan, “Cost-sensitive subspace learning for face recognition,”
in Proc. IEEE Conf. CVPR, Jun. 2010, pp. 2661–2666.</p>
<p>[4] X. Y. Liu and Z. H. Zhou, “Learning with cost intervals,” in Proc. ACM
SIGKDD, Washington, DC, USA, 2010, pp. 403–412.</p>
<p>[5] S. Yan, D. Xu, B. Zhang, H.-J. Zhang, Q. Yang, and S. Lin, “Graph
embedding and extensions: A general framework for dimensionality
reduction,” IEEE Trans. Pattern Anal. Mach. Intell., vol. 29, no. 1,
pp. 40–51, Jan. 2007.</p>
</div>



