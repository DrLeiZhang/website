---
layout: default
---
<img class="about-avatar" src="{{ "/img/object.jpg" | prepend: site.baseurl }}" border="0" alt="[name]" />

<div class="well">
<p><a href="http://www.leizhang.tk/">{Home}</a> <a href="http://www.leizhang.tk/publications%20and%20codes.html">{Publications and Codes}</a> <a href="http://www.leizhang.tk/research.html">{Research}</a> <a href="http://www.leizhang.tk/projects.html"><B>{Projects}</B></a> <a href="http://www.leizhang.tk/professional%20activities.html">{Professional Activities}</a> <a href="http://www.leizhang.tk/people.html">{People}</a></p>
</div>

<div class="well">
<h2>Machine Vision, Image Recognition and Machine Learning</h2>

<h1>[Proj-2: CRTL fro Cross-domain Image Recognition]</a></h1>
<p><B>Paper:</B> </p>
<p>Shanshan Wang, Lei Zhang*, and Wangmeng Zuo, Class-specific Reconstruction Transfer Learning via Sparse Low-rank Constraint, IEEE Int'Conf. Computer Vision (<B>ICCV</B>), in CEFRL Workshop, Oral presentation, 2017. <a href="resources/ICCVW_CRTL.pdf">[paper]</a></p>

<p><B>Abstract:</B></p>
<p>Subspace learning and reconstruction have been widely
explored in recent transfer learning work and generally
a specially designed projection and reconstruction transfer
matrix are wanted. However, existing subspace reconstruction
based algorithms neglect the class prior such that
the learned transfer function is biased, especially when data
scarcity of some class is encountered. Different from
those previous methods, in this paper, we propose a novel
reconstruction-based transfer learning method called
Class-specific Reconstruction Transfer Learning (CRTL),
which optimizes a well-designed transfer loss function without
class bias. Using a class-specific reconstruction matrix
to align the source domain with the target domain
which provides help for classification with class prior modeling.
Furthermore, to keep the intrinsic relationship between
data and labels after feature augmentation, a projected
Hilbert-Schmidt Independence Criterion (pHSIC), that
measures the dependency between two sets, is first proposed
by mapping the data from original space to RKHS in transfer
learning. In addition, combining low-rank and sparse
constraints on the class-specific reconstruction coefficient
matrix, the global and local data structures can be effectively
preserved. Extensive experiments demonstrate that the
proposed method outperforms conventional representationbased
domain adaptation methods.   </p>
<img class="about-avatar" src="{{ "/img/proj2_1.jpg" | prepend: site.baseurl }}" border="0" alt="[name]" />

<p><B>Approach:</B></p>
<p>Illustration of our proposed Class-specific Reconstruction Transfer Learning (CRTL)</p>
<img class="about-avatar" src="{{ "/img/proj2_2.jpg" | prepend: site.baseurl }}" border="0" alt="[name]" />

<p><B>Experiments:</B></p>
<p>Recognition accuracy (%) of different domain adaptation over 10 object categories on 4DA-CNN with deep feature
representation, COIL-20, face recognition across poses, and handwritten digits recognition.</p>
<img class="about-avatar" src="{{ "/img/proj2_3.jpg" | prepend: site.baseurl }}" border="0" alt="[name]" />
<img class="about-avatar" src="{{ "/img/proj2_4.jpg" | prepend: site.baseurl }}" border="0" alt="[name]" />

<p><B>References:</B></p>
<p>[1] L. Zhang,W. Zuo, and D. Zhang. Lsdt: Latent sparse domain
transfer learning for visual adaptation. IEEE Trans Image
Process, 25(3):1177–1191, 2016.</p>
<p>[2] Y. Xu, X. Fang, J. Wu, X. Li, and D. Zhang. Discriminative
transfer subspace learning via low-rank and sparse representation.
IEEE Trans Image Process, 25(2):850–863, 2015.</p>
<p>[3] M. Shao, D. Kit, and Y. Fu. Generalized transfer subspace
learning through low-rank constraint. IJCV, 109(1):74–93,
2014.</p>
<p>[4] G. Liu, Z. Lin, and Y. Yu. Robust subspace segmentation by
low-rank representation. In ICML, pages 663–670, 2010.</p>
</div>



